# H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng Speech-to-Text API

T√†i li·ªáu n√†y h∆∞·ªõng d·∫´n c√°ch s·ª≠ d·ª•ng t√≠nh nƒÉng Speech-to-Text (chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n) trong Medical Chatbot API.

## T·ªïng Quan

Speech-to-Text API cho ph√©p b·∫°n:
- ‚úÖ Chuy·ªÉn ƒë·ªïi file audio th√†nh vƒÉn b·∫£n (ti·∫øng Vi·ªát)
- ‚úÖ G·ª≠i c√¢u h·ªèi b·∫±ng gi·ªçng n√≥i cho chatbot y t·∫ø
- ‚úÖ H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng audio: mp3, wav, m4a, webm, ogg, flac
- ‚úÖ Gi·ªõi h·∫°n file: 25MB

## Y√™u C·∫ßu H·ªá Th·ªëng

### 1. C√†i ƒê·∫∑t FFmpeg

Speech-to-Text s·ª≠ d·ª•ng OpenAI Whisper, c·∫ßn c√≥ **ffmpeg** tr√™n h·ªá th·ªëng.

**Windows:**
```bash
# C√°ch 1: D√πng Chocolatey
choco install ffmpeg

# C√°ch 2: T·∫£i t·ª´ ffmpeg.org
# 1. T·∫£i t·ª´: https://ffmpeg.org/download.html
# 2. Gi·∫£i n√©n v√† th√™m v√†o PATH
```

**Linux:**
```bash
sudo apt update
sudo apt install ffmpeg
```

**Mac:**
```bash
brew install ffmpeg
```

**Ki·ªÉm tra c√†i ƒë·∫∑t:**
```bash
ffmpeg -version
```

### 2. Dependencies Python

ƒê√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t t·ª± ƒë·ªông qua `requirements.txt`:
```
openai-whisper==20231117
ffmpeg-python==0.2.0
```

## API Endpoints

### 1. Health Check

Ki·ªÉm tra xem Speech service c√≥ ho·∫°t ƒë·ªông kh√¥ng.

**Endpoint:** `GET /api/speech/health`

**Request:**
```bash
curl http://localhost:5000/api/speech/health
```

**Response:**
```json
{
  "success": true,
  "service": "speech-to-text",
  "status": "healthy",
  "model": "base",
  "model_loaded": true,
  "whisper_version": "20231117"
}
```

---

### 2. Transcribe Audio (Chuy·ªÉn Audio Th√†nh Text)

Chuy·ªÉn ƒë·ªïi file audio th√†nh vƒÉn b·∫£n.

**Endpoint:** `POST /api/speech/transcribe`

**Authentication:** Kh√¥ng c·∫ßn (public endpoint)

**Request:**

**V·ªõi cURL:**
```bash
curl -X POST http://localhost:5000/api/speech/transcribe \
  -F "audio=@path/to/your/audio.mp3" \
  -F "language=vi"
```

**V·ªõi Python:**
```python
import requests

url = "http://localhost:5000/api/speech/transcribe"

# M·ªü file audio
with open("audio.mp3", "rb") as audio_file:
    files = {"audio": audio_file}
    data = {"language": "vi"}  # T√πy ch·ªçn: vi, en, auto
    
    response = requests.post(url, files=files, data=data)
    result = response.json()
    
    print(f"Text: {result['text']}")
    print(f"Language: {result['language']}")
```

**V·ªõi JavaScript (Browser):**
```javascript
const formData = new FormData();
formData.append('audio', audioFile);  // audioFile l√† File object
formData.append('language', 'vi');

fetch('http://localhost:5000/api/speech/transcribe', {
  method: 'POST',
  body: formData
})
.then(response => response.json())
.then(data => {
  console.log('Text:', data.text);
  console.log('Language:', data.language);
});
```

**Parameters:**

| Tham s·ªë | Ki·ªÉu | B·∫Øt bu·ªôc | M√¥ t·∫£ |
|---------|------|----------|-------|
| `audio` | File | ‚úÖ C√≥ | File audio (mp3, wav, m4a, webm, ogg, flac). Max: 25MB |
| `language` | String | ‚ùå Kh√¥ng | M√£ ng√¥n ng·ªØ: `vi` (Ti·∫øng Vi·ªát), `en` (English), `auto` (t·ª± ƒë·ªông). M·∫∑c ƒë·ªãnh: `vi` |

**Response Success (200):**
```json
{
  "success": true,
  "text": "T√¥i b·ªã ƒëau ƒë·∫ßu v√† s·ªët cao",
  "language": "vi",
  "duration": 3.5,
  "message": "Transcription successful"
}
```

**Response Error (400):**
```json
{
  "success": false,
  "message": "File format not supported. Allowed: mp3, wav, m4a, webm, ogg, flac"
}
```

---

### 3. Speech-to-Chat (H·ªèi Chatbot B·∫±ng Gi·ªçng N√≥i)

Chuy·ªÉn audio th√†nh text v√† t·ª± ƒë·ªông h·ªèi chatbot y t·∫ø.

**Endpoint:** `POST /api/speech/chat`

**Authentication:** ‚úÖ Y√™u c·∫ßu JWT Token

**Request:**

**V·ªõi cURL:**
```bash
curl -X POST http://localhost:5000/api/speech/chat \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -F "audio=@question.mp3" \
  -F "language=vi" \
  -F "conversation_id=123"
```

**V·ªõi Python:**
```python
import requests

url = "http://localhost:5000/api/speech/chat"
headers = {"Authorization": "Bearer YOUR_JWT_TOKEN"}

with open("question.mp3", "rb") as audio_file:
    files = {"audio": audio_file}
    data = {
        "language": "vi",
        "conversation_id": 123  # T√πy ch·ªçn: ƒë·ªÉ ti·∫øp t·ª•c cu·ªôc h·ªôi tho·∫°i c≈©
    }
    
    response = requests.post(url, files=files, data=data, headers=headers)
    result = response.json()
    
    print(f"C√¢u h·ªèi: {result['transcribed_text']}")
    print(f"Tr·∫£ l·ªùi: {result['answer']}")
```

**V·ªõi JavaScript (Browser):**
```javascript
const formData = new FormData();
formData.append('audio', audioFile);
formData.append('language', 'vi');
formData.append('conversation_id', '123');  // Optional

fetch('http://localhost:5000/api/speech/chat', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer ' + jwtToken
  },
  body: formData
})
.then(response => response.json())
.then(data => {
  console.log('C√¢u h·ªèi:', data.transcribed_text);
  console.log('Tr·∫£ l·ªùi:', data.answer);
});
```

**Parameters:**

| Tham s·ªë | Ki·ªÉu | B·∫Øt bu·ªôc | M√¥ t·∫£ |
|---------|------|----------|-------|
| `audio` | File | ‚úÖ C√≥ | File audio ch·ª©a c√¢u h·ªèi |
| `language` | String | ‚ùå Kh√¥ng | M√£ ng√¥n ng·ªØ (m·∫∑c ƒë·ªãnh: `vi`) |
| `conversation_id` | Integer | ‚ùå Kh√¥ng | ID cu·ªôc h·ªôi tho·∫°i (ƒë·ªÉ ti·∫øp t·ª•c chat c≈©) |

**Headers:**

| Header | Gi√° tr·ªã |
|--------|---------|
| `Authorization` | `Bearer <JWT_TOKEN>` |

**Response Success (200):**
```json
{
  "success": true,
  "transcribed_text": "Tri·ªáu ch·ª©ng c·ªßa b·ªánh ti·ªÉu ƒë∆∞·ªùng l√† g√¨?",
  "question": "Tri·ªáu ch·ª©ng c·ªßa b·ªánh ti·ªÉu ƒë∆∞·ªùng l√† g√¨?",
  "answer": "C√°c tri·ªáu ch·ª©ng c·ªßa b·ªánh ti·ªÉu ƒë∆∞·ªùng bao g·ªìm: ƒëi ti·ªÉu nhi·ªÅu, kh√°t n∆∞·ªõc th∆∞·ªùng xuy√™n, m·ªát m·ªèi, s·ª•t c√¢n kh√¥ng r√µ nguy√™n nh√¢n...",
  "sources": [
    {
      "content": "...",
      "metadata": {...}
    }
  ],
  "conversation_id": 123,
  "message_id": 456,
  "language": "vi",
  "duration": 4.2
}
```

**Response Error (401 - Unauthorized):**
```json
{
  "success": false,
  "message": "Token is missing or invalid"
}
```

---

## C√°ch L·∫•y JWT Token

ƒê·ªÉ s·ª≠ d·ª•ng endpoint `/speech/chat`, b·∫°n c·∫ßn JWT token:

### 1. ƒêƒÉng K√Ω T√†i Kho·∫£n

```bash
curl -X POST http://localhost:5000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "password": "your_password",
    "full_name": "Your Name"
  }'
```

### 2. ƒêƒÉng Nh·∫≠p

```bash
curl -X POST http://localhost:5000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "password": "your_password"
  }'
```

**Response:**
```json
{
  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "user": {...}
}
```

S·ª≠ d·ª•ng `token` n√†y cho header `Authorization: Bearer <token>`.

---

## Test API v·ªõi Postman

### 1. Import v√†o Postman

T·∫°o collection m·ªõi v·ªõi c√°c request sau:

**Request 1: Transcribe**
- Method: `POST`
- URL: `http://localhost:5000/api/speech/transcribe`
- Body: `form-data`
  - Key: `audio`, Type: `File`, Value: ch·ªçn file audio
  - Key: `language`, Type: `Text`, Value: `vi`

**Request 2: Speech-to-Chat**
- Method: `POST`
- URL: `http://localhost:5000/api/speech/chat`
- Headers:
  - Key: `Authorization`, Value: `Bearer YOUR_JWT_TOKEN`
- Body: `form-data`
  - Key: `audio`, Type: `File`, Value: ch·ªçn file audio
  - Key: `language`, Type: `Text`, Value: `vi`

### 2. Test v·ªõi Swagger UI

1. M·ªü tr√¨nh duy·ªát: `http://localhost:5000/docs`
2. T√¨m section **speech**
3. Click v√†o endpoint mu·ªën test
4. Click **"Try it out"**
5. Upload file audio
6. (N·∫øu c·∫ßn) Click **Authorize** v√† nh·∫≠p JWT token
7. Click **Execute**

---

## V√≠ D·ª• Th·ª±c T·∫ø

### V√≠ D·ª• 1: Ghi √Çm v√† H·ªèi Chatbot (Python)

```python
import requests
import sounddevice as sd
import soundfile as sf
import numpy as np

# 1. Ghi √¢m t·ª´ microphone (3 gi√¢y)
print("ƒêang ghi √¢m... H√£y n√≥i c√¢u h·ªèi c·ªßa b·∫°n!")
duration = 3  # gi√¢y
sample_rate = 16000

audio_data = sd.rec(int(duration * sample_rate), 
                    samplerate=sample_rate, 
                    channels=1)
sd.wait()
print("Ghi √¢m xong!")

# 2. L∆∞u th√†nh file
sf.write("question.wav", audio_data, sample_rate)

# 3. G·ª≠i l√™n API
url = "http://localhost:5000/api/speech/chat"
headers = {"Authorization": "Bearer YOUR_JWT_TOKEN"}

with open("question.wav", "rb") as f:
    files = {"audio": f}
    response = requests.post(url, files=files, headers=headers)

result = response.json()
print(f"\nC√¢u h·ªèi: {result['transcribed_text']}")
print(f"Tr·∫£ l·ªùi: {result['answer']}")
```

### V√≠ D·ª• 2: Web Interface ƒê∆°n Gi·∫£n (HTML + JavaScript)

```html
<!DOCTYPE html>
<html>
<head>
    <title>Speech-to-Text Medical Chatbot</title>
</head>
<body>
    <h1>H·ªèi Chatbot B·∫±ng Gi·ªçng N√≥i</h1>
    
    <button id="recordBtn">üé§ Ghi √Çm</button>
    <button id="stopBtn" disabled>‚èπ D·ª´ng</button>
    
    <div id="result"></div>
    
    <script>
        let mediaRecorder;
        let audioChunks = [];
        const JWT_TOKEN = 'YOUR_JWT_TOKEN';  // Thay b·∫±ng token th·ª±c
        
        // B·∫Øt ƒë·∫ßu ghi √¢m
        document.getElementById('recordBtn').onclick = async () => {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            
            mediaRecorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };
            
            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                audioChunks = [];
                
                // G·ª≠i l√™n API
                const formData = new FormData();
                formData.append('audio', audioBlob, 'question.webm');
                formData.append('language', 'vi');
                
                const response = await fetch('http://localhost:5000/api/speech/chat', {
                    method: 'POST',
                    headers: { 'Authorization': 'Bearer ' + JWT_TOKEN },
                    body: formData
                });
                
                const result = await response.json();
                document.getElementById('result').innerHTML = `
                    <p><strong>C√¢u h·ªèi:</strong> ${result.transcribed_text}</p>
                    <p><strong>Tr·∫£ l·ªùi:</strong> ${result.answer}</p>
                `;
            };
            
            mediaRecorder.start();
            document.getElementById('recordBtn').disabled = true;
            document.getElementById('stopBtn').disabled = false;
        };
        
        // D·ª´ng ghi √¢m
        document.getElementById('stopBtn').onclick = () => {
            mediaRecorder.stop();
            document.getElementById('recordBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        };
    </script>
</body>
</html>
```

---

## Troubleshooting

### L·ªói: "ffmpeg not found"

**Nguy√™n nh√¢n:** Ch∆∞a c√†i ƒë·∫∑t ffmpeg ho·∫∑c ch∆∞a th√™m v√†o PATH.

**Gi·∫£i ph√°p:**
1. C√†i ƒë·∫∑t ffmpeg (xem ph·∫ßn Y√™u C·∫ßu H·ªá Th·ªëng)
2. Ki·ªÉm tra: `ffmpeg -version`
3. Restart terminal/IDE sau khi c√†i

### L·ªói: "File too large"

**Nguy√™n nh√¢n:** File audio > 25MB.

**Gi·∫£i ph√°p:**
- N√©n file audio (gi·∫£m bitrate)
- C·∫Øt file th√†nh nhi·ªÅu ƒëo·∫°n ng·∫Øn h∆°n
- Ho·∫∑c tƒÉng gi·ªõi h·∫°n trong `src/__init__.py`:
  ```python
  app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB
  ```

### L·ªói: "File format not supported"

**Nguy√™n nh√¢n:** ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£.

**Gi·∫£i ph√°p:**
- Chuy·ªÉn ƒë·ªïi sang format ƒë∆∞·ª£c h·ªó tr·ª£: mp3, wav, m4a, webm, ogg, flac
- D√πng ffmpeg ƒë·ªÉ convert:
  ```bash
  ffmpeg -i input.avi -acodec libmp3lame output.mp3
  ```

### L·ªói: "Unauthorized" (401)

**Nguy√™n nh√¢n:** JWT token kh√¥ng h·ª£p l·ªá ho·∫∑c h·∫øt h·∫°n.

**Gi·∫£i ph√°p:**
- ƒêƒÉng nh·∫≠p l·∫°i ƒë·ªÉ l·∫•y token m·ªõi
- Ki·ªÉm tra header `Authorization: Bearer <token>`
- ƒê·∫£m b·∫£o token ch∆∞a h·∫øt h·∫°n (m·∫∑c ƒë·ªãnh: 24h)

### Transcription Kh√¥ng Ch√≠nh X√°c

**Gi·∫£i ph√°p:**
1. **C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng audio:**
   - Ghi √¢m trong m√¥i tr∆∞·ªùng y√™n tƒ©nh
   - N√≥i r√µ r√†ng, kh√¥ng qu√° nhanh
   - S·ª≠ d·ª•ng microphone t·ªët

2. **Th·ª≠ model l·ªõn h∆°n:**
   S·ª≠a trong `src/services/speech_service.py`:
   ```python
   speech_service = SpeechService(model_name='small')  # ho·∫∑c 'medium'
   ```

3. **Ch·ªâ ƒë·ªãnh ng√¥n ng·ªØ:**
   ```python
   data = {"language": "vi"}  # Thay v√¨ "auto"
   ```

---

## Performance Tips

### 1. Model Size vs Speed

| Model | Size | Speed | ƒê·ªô ch√≠nh x√°c |
|-------|------|-------|--------------|
| tiny | 75MB | R·∫•t nhanh | Th·∫•p |
| base | 150MB | Nhanh | Trung b√¨nh ‚≠ê |
| small | 500MB | Trung b√¨nh | Cao |
| medium | 1.5GB | Ch·∫≠m | R·∫•t cao |

**Khuy·∫øn ngh·ªã:** D√πng `base` cho production.

### 2. Caching Model

Model ƒë∆∞·ª£c load l·∫ßn ƒë·∫ßu ti√™n khi g·ªçi API (lazy loading). L·∫ßn g·ªçi ƒë·∫ßu ti√™n s·∫Ω ch·∫≠m h∆°n (~10-30s), c√°c l·∫ßn sau nhanh h∆°n.

### 3. Concurrent Requests

Service h·ªó tr·ª£ x·ª≠ l√Ω nhi·ªÅu request ƒë·ªìng th·ªùi, nh∆∞ng m·ªói request s·∫Ω t·ªën ~1-2GB RAM.

**Khuy·∫øn ngh·ªã:** Gi·ªõi h·∫°n concurrent requests n·∫øu server c√≥ √≠t RAM.

---

## Li√™n H·ªá & H·ªó Tr·ª£

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, vui l√≤ng:
1. Ki·ªÉm tra logs trong terminal
2. Xem ph·∫ßn Troubleshooting ·ªü tr√™n
3. T·∫°o issue tr√™n GitHub repository

---

**Ch√∫c b·∫°n s·ª≠ d·ª•ng th√†nh c√¥ng! üéâ**
